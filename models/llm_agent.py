import os
import asyncio
import requests
import json
import random
from typing import Dict, List

class LocalGuideAgent:
    def __init__(self):
        self.max_tokens = 300  # Increased for richer responses
        self.temperature = 0.9  # Higher creativity
        self.working_provider = None
        self.groq_api_key = None
        self.openai_api_key = None

        # Initialize APIs
        if os.getenv('GROQ_API_KEY'):
            self.groq_api_key = os.getenv('GROQ_API_KEY').strip()
            self.working_provider = 'groq'
            print(f"тЬЕ Groq API key loaded: {self.groq_api_key[:10]}...")
        
        if os.getenv('OPENAI_API_KEY'):
            self.openai_api_key = os.getenv('OPENAI_API_KEY').strip()
            if not self.working_provider:
                self.working_provider = 'openai'
            print(f"тЬЕ OpenAI API key loaded: {self.openai_api_key[:10]}...")
        
        if not self.working_provider:
            raise Exception("тЭМ NO LLM API KEYS FOUND! Cannot operate without LLM.")

    async def get_response(self, user_message: str, conversation_history: List[Dict], user_context: Dict) -> str:
        """ALWAYS generate dynamic LLM response - NO FALLBACKS ALLOWED."""

        detected_lang = user_context.get('detected_language', 'en')
        print(f"ЁЯФД MANDATORY LLM call for {detected_lang}: '{user_message[:50]}...'")

        # Try primary LLM provider
        try:
            if self.working_provider == 'groq':
                response = await self._call_groq(user_message, user_context, conversation_history)
                print(f"тЬЕ GROQ SUCCESS: {response[:100]}...")
                return response
            elif self.working_provider == 'openai':
                response = await self._call_openai(user_message, user_context, conversation_history)
                print(f"тЬЕ OPENAI SUCCESS: {response[:100]}...")
                return response
        except Exception as e:
            print(f"тЭМ Primary LLM failed: {e}")

        # Try backup provider if available
        try:
            if self.working_provider == 'groq' and self.openai_api_key:
                print("ЁЯФД Trying OpenAI as backup...")
                response = await self._call_openai(user_message, user_context, conversation_history)
                return response
            elif self.working_provider == 'openai' and self.groq_api_key:
                print("ЁЯФД Trying Groq as backup...")
                response = await self._call_groq(user_message, user_context, conversation_history)
                return response
        except Exception as e:
            print(f"тЭМ Backup LLM failed: {e}")

        # ABSOLUTE LAST RESORT - Simple generative response
        return self._generate_emergency_response(user_message, user_context)

    async def _call_groq(self, user_message: str, user_context: Dict, conversation_history: List[Dict]) -> str:
        """Enhanced Groq API call with aggressive prompting."""

        url = "https://api.groq.com/openai/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {self.groq_api_key}",
            "Content-Type": "application/json"
        }

        messages = self._build_conversation_messages(user_message, user_context, conversation_history)

        payload = {
            "model": "llama3-8b-8192",
            "messages": messages,
            "max_tokens": self.max_tokens,
            "temperature": self.temperature,
            "top_p": 0.95,
            "stream": False
        }

        def send_request():
            return requests.post(url, headers=headers, json=payload, proxies={}, timeout=30)

        response = await asyncio.get_event_loop().run_in_executor(None, send_request)
        
        if response.status_code == 200:
            data = response.json()
            content = data['choices'][0]['message']['content'].strip()
            return content
        else:
            raise Exception(f"Groq API error {response.status_code}: {response.text[:300]}")

    async def _call_openai(self, user_message: str, user_context: Dict, conversation_history: List[Dict]) -> str:
        """Enhanced OpenAI API call with aggressive prompting."""

        url = "https://api.openai.com/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {self.openai_api_key}",
            "Content-Type": "application/json"
        }

        messages = self._build_conversation_messages(user_message, user_context, conversation_history)

        payload = {
            "model": "gpt-3.5-turbo",
            "messages": messages,
            "max_tokens": self.max_tokens,
            "temperature": self.temperature
        }

        def send_request():
            return requests.post(url, headers=headers, json=payload, proxies={}, timeout=30)

        response = await asyncio.get_event_loop().run_in_executor(None, send_request)

        if response.status_code == 200:
            data = response.json()
            content = data['choices'][0]['message']['content'].strip()
            return content
        else:
            raise Exception(f"OpenAI API error {response.status_code}: {response.text[:300]}")

    def _build_conversation_messages(self, user_message: str, user_context: Dict, conversation_history: List[Dict]) -> List[Dict]:
        """Build ultra-strong conversation messages."""
        
        system_prompt = self._build_ultimate_system_prompt(user_context, user_message)
        messages = [{"role": "system", "content": system_prompt}]
        
        # Add conversation history with context
        for msg in conversation_history[-6:]:  # More history for better context
            if msg.get('role') and msg.get('content'):
                messages.append({
                    "role": msg['role'],
                    "content": msg['content']
                })
        
        messages.append({"role": "user", "content": user_message})
        return messages

    def _build_ultimate_system_prompt(self, user_context: Dict, user_message: str) -> str:
        """Build the most aggressive, dynamic system prompt possible."""

        language_code = user_context.get('detected_language', 'en')
        location = user_context.get('current_location', 'India')
        mood = user_context.get('mood', 'curious')
        conversation_turns = user_context.get('conversation_turns', 1)
        wants_voice = user_context.get('wants_voice_response', False)

        # Ultra-dynamic language rules
        language_rules = {
            'en': {
                'name': 'English',
                'rule': 'RESPOND ONLY IN ENGLISH',
                'greeting': 'Welcome to incredible India!',
                'example': 'The Red Fort is magnificent! Built by Shah Jahan in 1648, it housed Mughal emperors.'
            },
            'hi': {
                'name': 'Hindi',
                'rule': 'рдХреЗрд╡рд▓ рд╣рд┐рдВрджреА рдореЗрдВ рдЬрд╡рд╛рдм рджреЗрдВ - ABSOLUTELY NO ENGLISH',
                'greeting': 'рдЕрд╡рд┐рд╢реНрд╡рд╕рдиреАрдп рднрд╛рд░рдд рдореЗрдВ рдЖрдкрдХрд╛ рд╕реНрд╡рд╛рдЧрдд рд╣реИ!',
                'example': 'рд▓рд╛рд▓ рдХрд┐рд▓рд╛ рд╢рд╛рдирджрд╛рд░ рд╣реИ! рд╢рд╛рд╣рдЬрд╣рд╛рдБ рдиреЗ 1648 рдореЗрдВ рдмрдирд╡рд╛рдпрд╛ рдерд╛, рдпрд╣рд╛рдБ рдореБрдЧрд▓ рд╕рдореНрд░рд╛рдЯ рд░рд╣рддреЗ рдереЗред'
            },
            'bn': {
                'name': 'Bengali',
                'rule': 'рж╢рзБржзрзБржорж╛рждрзНрж░ ржмрж╛ржВрж▓рж╛ржпрж╝ ржЙрждрзНрждрж░ ржжрж┐ржи - ABSOLUTELY NO ENGLISH',
                'greeting': 'ржЕржмрж┐рж╢рзНржмрж╛рж╕рзНржп ржнрж╛рж░рждрзЗ ржЖржкржирж╛ржХрзЗ рж╕рзНржмрж╛ржЧрждржо!',
                'example': 'рж▓рж╛рж▓ ржХрзЗрж▓рзНрж▓рж╛ ржжрзБрж░рзНржжрж╛ржирзНржд! рж╢рж╛рж╣ржЬрж╛рж╣рж╛ржи рззрзмрзкрзо рж╕рж╛рж▓рзЗ ржирж┐рж░рзНржорж╛ржг ржХрж░рзЗржЫрж┐рж▓рзЗржи, ржПржЦрж╛ржирзЗ ржорзБржЧрж▓ рж╕ржорзНрж░рж╛ржЯрж░рж╛ ржерж╛ржХрждрзЗржиред'
            },
            'ta': {
                'name': 'Tamil',
                'rule': 'родрооро┐ро┤ро┐ро▓рпН роороЯрпНроЯрпБроорпЗ рокродро┐ро▓ро│ро┐роХрпНроХро╡рпБроорпН - ABSOLUTELY NO ENGLISH',
                'greeting': 'роироорпНрокроорпБроЯро┐ропро╛род роЗроирпНродро┐ропро╛ро╡ро┐ро▒рпНроХрпБ ро╡ро░рпБроХ!',
                'example': 'роЪро┐ро╡рокрпНрокрпБ роХрпЛроЯрпНроЯрпИ роЕро▒рпНрокрпБродрооро╛ройродрпБ! ро╖ро╛роЬро╣ро╛ройрпН 1648-роЗро▓рпН роХроЯрпНроЯро┐ройро╛ро░рпН, роорпБроХро▓ро╛роп рооройрпНройро░рпНроХро│рпН роЗроЩрпНроХрпБ ро╡ро╛ро┤рпНроирпНродройро░рпНред'
            },
            'te': {
                'name': 'Telugu',
                'rule': 'р░др▒Жр░▓р▒Бр░Чр▒Бр░▓р▒Л р░ор░╛р░др▒Нр░░р░ор▒З р░╕р░ор░╛р░зр░╛р░ир░В р░Зр░╡р▒Нр░╡р░Вр░бр░┐ - ABSOLUTELY NO ENGLISH',
                'greeting': 'р░Ер░жр▒Нр░нр▒Бр░др░ор▒Ир░и р░нр░╛р░░р░др░жр▒Зр░╢р░╛р░ир░┐р░Хр░┐ р░╕р▒Нр░╡р░╛р░Чр░др░В!',
                'example': 'р░Ор░░р▒Нр░░р░Хр▒Лр░Я р░Ер░жр▒Нр░нр▒Бр░др░ор▒Ир░ир░жр░┐! р░╖р░╛р░Ьр░╣р░╛р░ир▒Н 1648р░▓р▒Л р░ир░┐р░░р▒Нр░ор░┐р░Вр░Ър░╛р░бр▒Б, р░ор▒Кр░Шр░▓р▒Н р░Ър░Хр▒Нр░░р░╡р░░р▒Нр░др▒Бр░▓р▒Б р░Зр░Хр▒Нр░Хр░б р░ир░┐р░╡р░╕р░┐р░Вр░Ър░╛р░░р▒Бред'
            },
            'ml': {
                'name': 'Malayalam',
                'rule': 'р┤ор┤▓р┤пр┤╛р┤│р┤др╡Нр┤др┤┐р╡╜ р┤ор┤╛р┤др╡Нр┤░р┤В р┤ор┤▒р╡Бр┤кр┤Яр┤┐ р┤ир╡╜р┤Хр╡Бр┤Х - ABSOLUTELY NO ENGLISH',
                'greeting': 'р┤Ер┤╡р┤┐р┤╢р╡Нр┤╡р┤╕р┤ир╡Ар┤пр┤ор┤╛р┤п р┤Зр┤ир╡Нр┤др╡Нр┤пр┤пр┤┐р┤▓р╡Зр┤Хр╡Нр┤Хр╡Н р┤╕р╡Нр┤╡р┤╛р┤Чр┤др┤В!',
                'example': 'р┤Ър╡Бр┤╡р┤ир╡Нр┤и р┤Хр╡Лр┤Яр╡Нр┤Я р┤Ер┤╡р┤┐р┤╢р╡Нр┤╡р┤╕р┤ир╡Ар┤пр┤ор┤╛р┤гр╡Н! р┤╖р┤╛р┤Ьр┤╣р┤╛р╡╗ 1648-р╡╜ р┤ир┤┐р╡╝р┤ор╡Нр┤ор┤┐р┤Ър╡Нр┤Ър╡Б, р┤ор╡Бр┤Чр╡╛ р┤Ър┤Хр╡Нр┤░р┤╡р╡╝р┤др╡Нр┤др┤┐р┤ор┤╛р╡╝ р┤Зр┤╡р┤┐р┤Яр╡Ж р┤др┤╛р┤ор┤╕р┤┐р┤Ър╡Нр┤Ър╡Бред'
            }
        }

        lang_info = language_rules.get(language_code, language_rules['en'])

        # Dynamic context integration
        context_elements = []
        if location:
            context_elements.append(f"Current focus: {location}")
        if mood != 'curious':
            context_elements.append(f"User mood: {mood}")
        if conversation_turns > 1:
            context_elements.append(f"Conversation turn: {conversation_turns}")
        if wants_voice:
            context_elements.append("VOICE RESPONSE REQUESTED - be more narrative and descriptive")

        context_string = " | ".join(context_elements) if context_elements else "Fresh conversation"

        # Voice-specific adjustments
        voice_instructions = ""
        if wants_voice:
            voice_instructions = f"""
ЁЯОд VOICE RESPONSE MODE ACTIVATED:
- Be more narrative and storytelling
- Use descriptive language that sounds good when spoken
- Add dramatic pauses with punctuation
- Make it engaging for audio consumption
- Paint vivid pictures with words
"""

        # Ultimate dynamic prompt
        prompt = f"""ЁЯМН You are CityChai, India's most passionate and knowledgeable AI tour guide.

ЁЯЪи CRITICAL LANGUAGE RULE ЁЯЪи
{lang_info['rule']}
USER LANGUAGE: {lang_info['name']}
YOU MUST RESPOND ONLY IN: {lang_info['name']}

CONTEXT: {context_string}

USER MESSAGE: "{user_message}"
CONVERSATION TURN: {conversation_turns}

{voice_instructions}

ЁЯОп RESPONSE REQUIREMENTS:
1. Generate COMPLETELY UNIQUE content - never repeat previous responses
2. Use ONLY {lang_info['name']} language - NO exceptions
3. Be conversational, engaging, and passionate about India
4. Include fascinating cultural details, stories, or insights
5. Reference location ({location}) and mood ({mood}) naturally
6. Keep responses 3-4 sentences but rich in content
7. Use emojis naturally but not excessively
8. End with an engaging question or suggestion when appropriate

ЁЯФе STYLE GUIDE:
- Be like a local friend who's deeply passionate about Indian culture
- Share insider knowledge and hidden gems
- Tell mini-stories or interesting facts
- Match the user's energy and interest level
- Be helpful, informative, and genuinely exciting

EXAMPLE PERFECT RESPONSE:
{lang_info['example']}

ЁЯМЯ Remember: This is turn {conversation_turns} of our conversation. Be contextual, dynamic, and absolutely passionate about India! Respond ONLY in {lang_info['name']}!"""

        return prompt.strip()

    def _generate_emergency_response(self, user_message: str, user_context: Dict) -> str:
        """Last resort generative response if all LLMs fail."""
        
        language_code = user_context.get('detected_language', 'en')
        location = user_context.get('current_location', 'India')
        
        emergency_responses = {
            'en': [
                f"I'm deeply passionate about helping you discover {location or 'India'}! Even though I'm having technical difficulties, I can tell you that every corner of India has incredible stories waiting to be shared. What specific aspect interests you most?",
                f"India's rich heritage in {location or 'every region'} never fails to amaze me! While I'm experiencing some connectivity issues, I'd love to continue our conversation about this incredible destination. What would you like to explore?",
                f"The magic of {location or 'India'} is truly endless! Despite some technical challenges, I'm here to share the wonders of Indian culture and history with you. What catches your curiosity today?"
            ],
            'hi': [
                f"{location or 'рднрд╛рд░рдд'} рдХреА рдЦреЛрдЬ рдореЗрдВ рдЖрдкрдХреА рдорджрдж рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдореИрдВ рдмрд╣реБрдд рдЙрддреНрд╕рд╛рд╣рд┐рдд рд╣реВрдВ! рддрдХрдиреАрдХреА рд╕рдорд╕реНрдпрд╛рдУрдВ рдХреЗ рдмрд╛рд╡рдЬреВрдж, рдореИрдВ рдЬрд╛рдирддрд╛ рд╣реВрдВ рдХрд┐ рднрд╛рд░рдд рдХреЗ рд╣рд░ рдХреЛрдиреЗ рдореЗрдВ рдЕрд╡рд┐рд╢реНрд╡рд╕рдиреАрдп рдХрд╣рд╛рдирд┐рдпрд╛рдВ рд╣реИрдВред рдЖрдк рдХрд┐рд╕ рд╡рд┐рд╢реЗрд╖ рдЪреАрдЬрд╝ рдореЗрдВ рд░реБрдЪрд┐ рд░рдЦрддреЗ рд╣реИрдВ?",
                f"{location or 'рд╣рд░ рдХреНрд╖реЗрддреНрд░'} рдореЗрдВ рднрд╛рд░рдд рдХреА рд╕рдореГрджреНрдз рд╡рд┐рд░рд╛рд╕рдд рдореБрдЭреЗ рд╣рдореЗрд╢рд╛ рдЖрд╢реНрдЪрд░реНрдпрдЪрдХрд┐рдд рдХрд░рддреА рд╣реИ! рдХреБрдЫ connectivity issues рдХреЗ рдмрд╛рд╡рдЬреВрдж, рдореИрдВ рдЗрд╕ рдЕрд╡рд┐рд╢реНрд╡рд╕рдиреАрдп рдЧрдВрддрд╡реНрдп рдХреЗ рдмрд╛рд░реЗ рдореЗрдВ рдмрд╛рддрдЪреАрдд рдЬрд╛рд░реА рд░рдЦрдирд╛ рдЪрд╛рд╣реВрдВрдЧрд╛ред рдЖрдк рдХреНрдпрд╛ explore рдХрд░рдирд╛ рдЪрд╛рд╣рддреЗ рд╣реИрдВ?"
            ],
            'bn': [
                f"{location or 'ржнрж╛рж░ржд'} ржЖржмрж┐рж╖рзНржХрж╛рж░рзЗ ржЖржкржирж╛ржХрзЗ рж╕рж╛рж╣рж╛ржпрзНржп ржХрж░рждрзЗ ржЖржорж┐ ржЧржнрзАрж░ржнрж╛ржмрзЗ ржЖржмрзЗржЧржкрзНрж░ржмржг! ржкрзНрж░ржпрзБржХрзНрждрж┐ржЧржд рж╕ржорж╕рзНржпрж╛ рж╕рждрзНрждрзНржмрзЗржУ, ржЖржорж┐ ржЬрж╛ржирж┐ ржнрж╛рж░рждрзЗрж░ ржкрзНрж░рждрж┐ржЯрж┐ ржХрзЛржгрзЗ ржЕржмрж┐рж╢рзНржмрж╛рж╕рзНржп ржЧрж▓рзНржк ржЕржкрзЗржХрзНрж╖рж╛ ржХрж░ржЫрзЗред ржХрзЛржи ржирж┐рж░рзНржжрж┐рж╖рзНржЯ ржмрж┐рж╖ржпрж╝ ржЖржкржирж╛рж░ ржЖржЧрзНрж░рж╣рзЗрж░?",
                f"{location or 'ржкрзНрж░рждрж┐ржЯрж┐ ржЕржЮрзНржЪрж▓рзЗ'} ржнрж╛рж░рждрзЗрж░ рж╕ржорзГржжрзНржз ржРрждрж┐рж╣рзНржп ржЖржорж╛ржХрзЗ рж╕рж░рзНржмржжрж╛ ржмрж┐рж╕рзНржорж┐ржд ржХрж░рзЗ! ржХрж┐ржЫрзБ connectivity рж╕ржорж╕рзНржпрж╛ рж╕рждрзНрждрзНржмрзЗржУ, ржЖржорж┐ ржПржЗ ржЕржмрж┐рж╢рзНржмрж╛рж╕рзНржп ржЧржирзНрждржмрзНржп ржирж┐ржпрж╝рзЗ ржХржерзЛржкржХржержи ржЪрж╛рж▓рж┐ржпрж╝рзЗ ржпрзЗрждрзЗ ржЪрж╛ржЗред ржЖржкржирж┐ ржХрзА ржЕржирзНржмрзЗрж╖ржг ржХрж░рждрзЗ ржЪрж╛ржи?"
            ]
        }
        
        responses = emergency_responses.get(language_code, emergency_responses['en'])
        return random.choice(responses)
