import os
import asyncio
import requests
import json
import random
from typing import Dict, List

class LocalGuideAgent:
    def __init__(self):
        self.max_tokens = 300  # Increased for richer responses
        self.temperature = 0.9  # Higher creativity
        self.working_provider = None
        self.groq_api_key = None
        self.openai_api_key = None

        # Initialize APIs
        if os.getenv('GROQ_API_KEY'):
            self.groq_api_key = os.getenv('GROQ_API_KEY').strip()
            self.working_provider = 'groq'
            print(f"‚úÖ Groq API key loaded: {self.groq_api_key[:10]}...")
        
        if os.getenv('OPENAI_API_KEY'):
            self.openai_api_key = os.getenv('OPENAI_API_KEY').strip()
            if not self.working_provider:
                self.working_provider = 'openai'
            print(f"‚úÖ OpenAI API key loaded: {self.openai_api_key[:10]}...")
        
        if not self.working_provider:
            raise Exception("‚ùå NO LLM API KEYS FOUND! Cannot operate without LLM.")

    async def get_response(self, user_message: str, conversation_history: List[Dict], user_context: Dict) -> str:
        """ALWAYS generate dynamic LLM response - NO FALLBACKS ALLOWED."""

        detected_lang = user_context.get('detected_language', 'en')
        print(f"üîÑ MANDATORY LLM call for {detected_lang}: '{user_message[:50]}...'")

        # Try primary LLM provider
        try:
            if self.working_provider == 'groq':
                response = await self._call_groq(user_message, user_context, conversation_history)
                print(f"‚úÖ GROQ SUCCESS: {response[:100]}...")
                return response
            elif self.working_provider == 'openai':
                response = await self._call_openai(user_message, user_context, conversation_history)
                print(f"‚úÖ OPENAI SUCCESS: {response[:100]}...")
                return response
        except Exception as e:
            print(f"‚ùå Primary LLM failed: {e}")

        # Try backup provider if available
        try:
            if self.working_provider == 'groq' and self.openai_api_key:
                print("üîÑ Trying OpenAI as backup...")
                response = await self._call_openai(user_message, user_context, conversation_history)
                return response
            elif self.working_provider == 'openai' and self.groq_api_key:
                print("üîÑ Trying Groq as backup...")
                response = await self._call_groq(user_message, user_context, conversation_history)
                return response
        except Exception as e:
            print(f"‚ùå Backup LLM failed: {e}")

        # ABSOLUTE LAST RESORT - Simple generative response
        return self._generate_emergency_response(user_message, user_context)

    async def _call_groq(self, user_message: str, user_context: Dict, conversation_history: List[Dict]) -> str:
        """Enhanced Groq API call with aggressive prompting."""

        url = "https://api.groq.com/openai/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {self.groq_api_key}",
            "Content-Type": "application/json"
        }

        messages = self._build_conversation_messages(user_message, user_context, conversation_history)

        payload = {
            "model": "llama3-8b-8192",
            "messages": messages,
            "max_tokens": self.max_tokens,
            "temperature": self.temperature,
            "top_p": 0.95,
            "stream": False
        }

        def send_request():
            return requests.post(url, headers=headers, json=payload, proxies={}, timeout=30)

        response = await asyncio.get_event_loop().run_in_executor(None, send_request)
        
        if response.status_code == 200:
            data = response.json()
            content = data['choices'][0]['message']['content'].strip()
            return content
        else:
            raise Exception(f"Groq API error {response.status_code}: {response.text[:300]}")

    async def _call_openai(self, user_message: str, user_context: Dict, conversation_history: List[Dict]) -> str:
        """Enhanced OpenAI API call with aggressive prompting."""

        url = "https://api.openai.com/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {self.openai_api_key}",
            "Content-Type": "application/json"
        }

        messages = self._build_conversation_messages(user_message, user_context, conversation_history)

        payload = {
            "model": "gpt-3.5-turbo",
            "messages": messages,
            "max_tokens": self.max_tokens,
            "temperature": self.temperature
        }

        def send_request():
            return requests.post(url, headers=headers, json=payload, proxies={}, timeout=30)

        response = await asyncio.get_event_loop().run_in_executor(None, send_request)

        if response.status_code == 200:
            data = response.json()
            content = data['choices'][0]['message']['content'].strip()
            return content
        else:
            raise Exception(f"OpenAI API error {response.status_code}: {response.text[:300]}")

    def _build_conversation_messages(self, user_message: str, user_context: Dict, conversation_history: List[Dict]) -> List[Dict]:
        """Build ultra-strong conversation messages."""
        
        system_prompt = self._build_ultimate_system_prompt(user_context, user_message)
        messages = [{"role": "system", "content": system_prompt}]
        
        # Add conversation history with context
        for msg in conversation_history[-6:]:  # More history for better context
            if msg.get('role') and msg.get('content'):
                messages.append({
                    "role": msg['role'],
                    "content": msg['content']
                })
        
        messages.append({"role": "user", "content": user_message})
        return messages

    def _build_ultimate_system_prompt(self, user_context: Dict, user_message: str) -> str:
        """Build the most aggressive, dynamic system prompt possible."""

        language_code = user_context.get('detected_language', 'en')
        location = user_context.get('current_location', 'India')
        mood = user_context.get('mood', 'curious')
        conversation_turns = user_context.get('conversation_turns', 1)
        wants_voice = user_context.get('wants_voice_response', False)

        # Ultra-dynamic language rules
        language_rules = {
            'en': {
                'name': 'English',
                'rule': 'RESPOND ONLY IN ENGLISH',
                'greeting': 'Welcome to incredible India!',
                'example': 'The Red Fort is magnificent! Built by Shah Jahan in 1648, it housed Mughal emperors.'
            },
            'hi': {
                'name': 'Hindi',
                'rule': '‡§ï‡•á‡§µ‡§≤ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§Ç - ABSOLUTELY NO ENGLISH',
                'greeting': '‡§Ö‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡§®‡•Ä‡§Ø ‡§≠‡§æ‡§∞‡§§ ‡§Æ‡•á‡§Ç ‡§Ü‡§™‡§ï‡§æ ‡§∏‡•ç‡§µ‡§æ‡§ó‡§§ ‡§π‡•à!',
                'example': '‡§≤‡§æ‡§≤ ‡§ï‡§ø‡§≤‡§æ ‡§∂‡§æ‡§®‡§¶‡§æ‡§∞ ‡§π‡•à! ‡§∂‡§æ‡§π‡§ú‡§π‡§æ‡§Å ‡§®‡•á 1648 ‡§Æ‡•á‡§Ç ‡§¨‡§®‡§µ‡§æ‡§Ø‡§æ ‡§•‡§æ, ‡§Ø‡§π‡§æ‡§Å ‡§Æ‡•Å‡§ó‡§≤ ‡§∏‡§Æ‡•ç‡§∞‡§æ‡§ü ‡§∞‡§π‡§§‡•á ‡§•‡•á‡•§'
            },
            'bn': {
                'name': 'Bengali',
                'rule': '‡¶∂‡ßÅ‡¶ß‡ßÅ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞ ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶Ø‡¶º ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶¶‡¶ø‡¶® - ABSOLUTELY NO ENGLISH',
                'greeting': '‡¶Ö‡¶¨‡¶ø‡¶∂‡ßç‡¶¨‡¶æ‡¶∏‡ßç‡¶Ø ‡¶≠‡¶æ‡¶∞‡¶§‡ßá ‡¶Ü‡¶™‡¶®‡¶æ‡¶ï‡ßá ‡¶∏‡ßç‡¶¨‡¶æ‡¶ó‡¶§‡¶Æ!',
                'example': '‡¶≤‡¶æ‡¶≤ ‡¶ï‡ßá‡¶≤‡ßç‡¶≤‡¶æ ‡¶¶‡ßÅ‡¶∞‡ßç‡¶¶‡¶æ‡¶®‡ßç‡¶§! ‡¶∂‡¶æ‡¶π‡¶ú‡¶æ‡¶π‡¶æ‡¶® ‡ßß‡ß¨‡ß™‡ßÆ ‡¶∏‡¶æ‡¶≤‡ßá ‡¶®‡¶ø‡¶∞‡ßç‡¶Æ‡¶æ‡¶£ ‡¶ï‡¶∞‡ßá‡¶õ‡¶ø‡¶≤‡ßá‡¶®, ‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶Æ‡ßÅ‡¶ó‡¶≤ ‡¶∏‡¶Æ‡ßç‡¶∞‡¶æ‡¶ü‡¶∞‡¶æ ‡¶•‡¶æ‡¶ï‡¶§‡ßá‡¶®‡•§'
            },
            'ta': {
                'name': 'Tamil',
                'rule': '‡Æ§‡ÆÆ‡Æø‡Æ¥‡Æø‡Æ≤‡Øç ‡ÆÆ‡Æü‡Øç‡Æü‡ØÅ‡ÆÆ‡Øá ‡Æ™‡Æ§‡Æø‡Æ≤‡Æ≥‡Æø‡Æï‡Øç‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç - ABSOLUTELY NO ENGLISH',
                'greeting': '‡Æ®‡ÆÆ‡Øç‡Æ™‡ÆÆ‡ØÅ‡Æü‡Æø‡ÆØ‡Ææ‡Æ§ ‡Æá‡Æ®‡Øç‡Æ§‡Æø‡ÆØ‡Ææ‡Æµ‡Æø‡Æ±‡Øç‡Æï‡ØÅ ‡Æµ‡Æ∞‡ØÅ‡Æï!',
                'example': '‡Æö‡Æø‡Æµ‡Æ™‡Øç‡Æ™‡ØÅ ‡Æï‡Øã‡Æü‡Øç‡Æü‡Øà ‡ÆÖ‡Æ±‡Øç‡Æ™‡ØÅ‡Æ§‡ÆÆ‡Ææ‡Æ©‡Æ§‡ØÅ! ‡Æ∑‡Ææ‡Æú‡Æπ‡Ææ‡Æ©‡Øç 1648-‡Æá‡Æ≤‡Øç ‡Æï‡Æü‡Øç‡Æü‡Æø‡Æ©‡Ææ‡Æ∞‡Øç, ‡ÆÆ‡ØÅ‡Æï‡Æ≤‡Ææ‡ÆØ ‡ÆÆ‡Æ©‡Øç‡Æ©‡Æ∞‡Øç‡Æï‡Æ≥‡Øç ‡Æá‡Æô‡Øç‡Æï‡ØÅ ‡Æµ‡Ææ‡Æ¥‡Øç‡Æ®‡Øç‡Æ§‡Æ©‡Æ∞‡Øç‡•§'
            },
            'te': {
                'name': 'Telugu',
                'rule': '‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å‡∞≤‡±ã ‡∞Æ‡∞æ‡∞§‡±ç‡∞∞‡∞Æ‡±á ‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç ‡∞á‡∞µ‡±ç‡∞µ‡∞Ç‡∞°‡∞ø - ABSOLUTELY NO ENGLISH',
                'greeting': '‡∞Ö‡∞¶‡±ç‡∞≠‡±Å‡∞§‡∞Æ‡±à‡∞® ‡∞≠‡∞æ‡∞∞‡∞§‡∞¶‡±á‡∞∂‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞∏‡±ç‡∞µ‡∞æ‡∞ó‡∞§‡∞Ç!',
                'example': '‡∞é‡∞∞‡±ç‡∞∞‡∞ï‡±ã‡∞ü ‡∞Ö‡∞¶‡±ç‡∞≠‡±Å‡∞§‡∞Æ‡±à‡∞®‡∞¶‡∞ø! ‡∞∑‡∞æ‡∞ú‡∞π‡∞æ‡∞®‡±ç 1648‡∞≤‡±ã ‡∞®‡∞ø‡∞∞‡±ç‡∞Æ‡∞ø‡∞Ç‡∞ö‡∞æ‡∞°‡±Å, ‡∞Æ‡±ä‡∞ò‡∞≤‡±ç ‡∞ö‡∞ï‡±ç‡∞∞‡∞µ‡∞∞‡±ç‡∞§‡±Å‡∞≤‡±Å ‡∞á‡∞ï‡±ç‡∞ï‡∞° ‡∞®‡∞ø‡∞µ‡∞∏‡∞ø‡∞Ç‡∞ö‡∞æ‡∞∞‡±Å‡•§'
            },
            'ml': {
                'name': 'Malayalam',
                'rule': '‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥§‡µç‡¥§‡¥ø‡µΩ ‡¥Æ‡¥æ‡¥§‡µç‡¥∞‡¥Ç ‡¥Æ‡¥±‡µÅ‡¥™‡¥ü‡¥ø ‡¥®‡µΩ‡¥ï‡µÅ‡¥ï - ABSOLUTELY NO ENGLISH',
                'greeting': '‡¥Ö‡¥µ‡¥ø‡¥∂‡µç‡¥µ‡¥∏‡¥®‡µÄ‡¥Ø‡¥Æ‡¥æ‡¥Ø ‡¥á‡¥®‡µç‡¥§‡µç‡¥Ø‡¥Ø‡¥ø‡¥≤‡µá‡¥ï‡µç‡¥ï‡µç ‡¥∏‡µç‡¥µ‡¥æ‡¥ó‡¥§‡¥Ç!',
                'example': '‡¥ö‡µÅ‡¥µ‡¥®‡µç‡¥® ‡¥ï‡µã‡¥ü‡µç‡¥ü ‡¥Ö‡¥µ‡¥ø‡¥∂‡µç‡¥µ‡¥∏‡¥®‡µÄ‡¥Ø‡¥Æ‡¥æ‡¥£‡µç! ‡¥∑‡¥æ‡¥ú‡¥π‡¥æ‡µª 1648-‡µΩ ‡¥®‡¥ø‡µº‡¥Æ‡µç‡¥Æ‡¥ø‡¥ö‡µç‡¥ö‡µÅ, ‡¥Æ‡µÅ‡¥ó‡µæ ‡¥ö‡¥ï‡µç‡¥∞‡¥µ‡µº‡¥§‡µç‡¥§‡¥ø‡¥Æ‡¥æ‡µº ‡¥á‡¥µ‡¥ø‡¥ü‡µÜ ‡¥§‡¥æ‡¥Æ‡¥∏‡¥ø‡¥ö‡µç‡¥ö‡µÅ‡•§'
            }
        }

        lang_info = language_rules.get(language_code, language_rules['en'])

        # Dynamic context integration
        context_elements = []
        if location:
            context_elements.append(f"Current focus: {location}")
        if mood != 'curious':
            context_elements.append(f"User mood: {mood}")
        if conversation_turns > 1:
            context_elements.append(f"Conversation turn: {conversation_turns}")
        if wants_voice:
            context_elements.append("VOICE RESPONSE REQUESTED - be more narrative and descriptive")

        context_string = " | ".join(context_elements) if context_elements else "Fresh conversation"

        # Voice-specific adjustments
        voice_instructions = ""
        if wants_voice:
            voice_instructions = f"""
üé§ VOICE RESPONSE MODE ACTIVATED:
- Be more narrative and storytelling
- Use descriptive language that sounds good when spoken
- Add dramatic pauses with punctuation
- Make it engaging for audio consumption
- Paint vivid pictures with words
"""

        # Ultimate dynamic prompt
        prompt = f"""üåç You are CityChai, India's most passionate and knowledgeable AI tour guide.

üö® CRITICAL LANGUAGE RULE üö®
{lang_info['rule']}
USER LANGUAGE: {lang_info['name']}
YOU MUST RESPOND ONLY IN: {lang_info['name']}

CONTEXT: {context_string}

USER MESSAGE: "{user_message}"
CONVERSATION TURN: {conversation_turns}

{voice_instructions}

üéØ RESPONSE REQUIREMENTS:
1. Generate COMPLETELY UNIQUE content - never repeat previous responses
2. Use ONLY {lang_info['name']} language - NO exceptions
3. Be conversational, engaging, and passionate about India
4. Include fascinating cultural details, stories, or insights
5. Reference location ({location}) and mood ({mood}) naturally
6. Keep responses 3-4 sentences but rich in content
7. Use emojis naturally but not excessively
8. End with an engaging question or suggestion when appropriate

üî• STYLE GUIDE:
- Be like a local friend who's deeply passionate about Indian culture
- Share insider knowledge and hidden gems
- Tell mini-stories or interesting facts
- Match the user's energy and interest level
- Be helpful, informative, and genuinely exciting

EXAMPLE PERFECT RESPONSE:
{lang_info['example']}

üåü Remember: This is turn {conversation_turns} of our conversation. Be contextual, dynamic, and absolutely passionate about India! Respond ONLY in {lang_info['name']}!"""

        return prompt.strip()

    def _generate_emergency_response(self, user_message: str, user_context: Dict) -> str:
        """Last resort generative response if all LLMs fail."""
        
        language_code = user_context.get('detected_language', 'en')
        location = user_context.get('current_location', 'India')
        
        emergency_responses = {
            'en': [
                f"I'm deeply passionate about helping you discover {location or 'India'}! Even though I'm having technical difficulties, I can tell you that every corner of India has incredible stories waiting to be shared. What specific aspect interests you most?",
                f"India's rich heritage in {location or 'every region'} never fails to amaze me! While I'm experiencing some connectivity issues, I'd love to continue our conversation about this incredible destination. What would you like to explore?",
                f"The magic of {location or 'India'} is truly endless! Despite some technical challenges, I'm here to share the wonders of Indian culture and history with you. What catches your curiosity today?"
            ],
            'hi': [
                f"{location or '‡§≠‡§æ‡§∞‡§§'} ‡§ï‡•Ä ‡§ñ‡•ã‡§ú ‡§Æ‡•á‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Æ‡•à‡§Ç ‡§¨‡§π‡•Å‡§§ ‡§â‡§§‡•ç‡§∏‡§æ‡§π‡§ø‡§§ ‡§π‡•Ç‡§Ç! ‡§§‡§ï‡§®‡•Ä‡§ï‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§¨‡§æ‡§µ‡§ú‡•Ç‡§¶, ‡§Æ‡•à‡§Ç ‡§ú‡§æ‡§®‡§§‡§æ ‡§π‡•Ç‡§Ç ‡§ï‡§ø ‡§≠‡§æ‡§∞‡§§ ‡§ï‡•á ‡§π‡§∞ ‡§ï‡•ã‡§®‡•á ‡§Æ‡•á‡§Ç ‡§Ö‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡§®‡•Ä‡§Ø ‡§ï‡§π‡§æ‡§®‡§ø‡§Ø‡§æ‡§Ç ‡§π‡•à‡§Ç‡•§ ‡§Ü‡§™ ‡§ï‡§ø‡§∏ ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§ö‡•Ä‡§ú‡§º ‡§Æ‡•á‡§Ç ‡§∞‡•Å‡§ö‡§ø ‡§∞‡§ñ‡§§‡•á ‡§π‡•à‡§Ç?",
                f"{location or '‡§π‡§∞ ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞'} ‡§Æ‡•á‡§Ç ‡§≠‡§æ‡§∞‡§§ ‡§ï‡•Ä ‡§∏‡§Æ‡•É‡§¶‡•ç‡§ß ‡§µ‡§ø‡§∞‡§æ‡§∏‡§§ ‡§Æ‡•Å‡§ù‡•á ‡§π‡§Æ‡•á‡§∂‡§æ ‡§Ü‡§∂‡•ç‡§ö‡§∞‡•ç‡§Ø‡§ö‡§ï‡§ø‡§§ ‡§ï‡§∞‡§§‡•Ä ‡§π‡•à! ‡§ï‡•Å‡§õ connectivity issues ‡§ï‡•á ‡§¨‡§æ‡§µ‡§ú‡•Ç‡§¶, ‡§Æ‡•à‡§Ç ‡§á‡§∏ ‡§Ö‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡§®‡•Ä‡§Ø ‡§ó‡§Ç‡§§‡§µ‡•ç‡§Ø ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§¨‡§æ‡§§‡§ö‡•Ä‡§§ ‡§ú‡§æ‡§∞‡•Ä ‡§∞‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡•Ç‡§Ç‡§ó‡§æ‡•§ ‡§Ü‡§™ ‡§ï‡•ç‡§Ø‡§æ explore ‡§ï‡§∞‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç?"
            ],
            'bn': [
                f"{location or '‡¶≠‡¶æ‡¶∞‡¶§'} ‡¶Ü‡¶¨‡¶ø‡¶∑‡ßç‡¶ï‡¶æ‡¶∞‡ßá ‡¶Ü‡¶™‡¶®‡¶æ‡¶ï‡ßá ‡¶∏‡¶æ‡¶π‡¶æ‡¶Ø‡ßç‡¶Ø ‡¶ï‡¶∞‡¶§‡ßá ‡¶Ü‡¶Æ‡¶ø ‡¶ó‡¶≠‡ßÄ‡¶∞‡¶≠‡¶æ‡¶¨‡ßá ‡¶Ü‡¶¨‡ßá‡¶ó‡¶™‡ßç‡¶∞‡¶¨‡¶£! ‡¶™‡ßç‡¶∞‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§‡¶ø‡¶ó‡¶§ ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶∏‡¶§‡ßç‡¶§‡ßç‡¶¨‡ßá‡¶ì, ‡¶Ü‡¶Æ‡¶ø ‡¶ú‡¶æ‡¶®‡¶ø ‡¶≠‡¶æ‡¶∞‡¶§‡ßá‡¶∞ ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶ï‡ßã‡¶£‡ßá ‡¶Ö‡¶¨‡¶ø‡¶∂‡ßç‡¶¨‡¶æ‡¶∏‡ßç‡¶Ø ‡¶ó‡¶≤‡ßç‡¶™ ‡¶Ö‡¶™‡ßá‡¶ï‡ßç‡¶∑‡¶æ ‡¶ï‡¶∞‡¶õ‡ßá‡•§ ‡¶ï‡ßã‡¶® ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶¨‡¶ø‡¶∑‡¶Ø‡¶º ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶Ü‡¶ó‡ßç‡¶∞‡¶π‡ßá‡¶∞?",
                f"{location or '‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶Ö‡¶û‡ßç‡¶ö‡¶≤‡ßá'} ‡¶≠‡¶æ‡¶∞‡¶§‡ßá‡¶∞ ‡¶∏‡¶Æ‡ßÉ‡¶¶‡ßç‡¶ß ‡¶ê‡¶§‡¶ø‡¶π‡ßç‡¶Ø ‡¶Ü‡¶Æ‡¶æ‡¶ï‡ßá ‡¶∏‡¶∞‡ßç‡¶¨‡¶¶‡¶æ ‡¶¨‡¶ø‡¶∏‡ßç‡¶Æ‡¶ø‡¶§ ‡¶ï‡¶∞‡ßá! ‡¶ï‡¶ø‡¶õ‡ßÅ connectivity ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶∏‡¶§‡ßç‡¶§‡ßç‡¶¨‡ßá‡¶ì, ‡¶Ü‡¶Æ‡¶ø ‡¶è‡¶á ‡¶Ö‡¶¨‡¶ø‡¶∂‡ßç‡¶¨‡¶æ‡¶∏‡ßç‡¶Ø ‡¶ó‡¶®‡ßç‡¶§‡¶¨‡ßç‡¶Ø ‡¶®‡¶ø‡¶Ø‡¶º‡ßá ‡¶ï‡¶•‡ßã‡¶™‡¶ï‡¶•‡¶® ‡¶ö‡¶æ‡¶≤‡¶ø‡¶Ø‡¶º‡ßá ‡¶Ø‡ßá‡¶§‡ßá ‡¶ö‡¶æ‡¶á‡•§ ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡ßÄ ‡¶Ö‡¶®‡ßç‡¶¨‡ßá‡¶∑‡¶£ ‡¶ï‡¶∞‡¶§‡ßá ‡¶ö‡¶æ‡¶®?"
            ]
        }
        
        responses = emergency_responses.get(language_code, emergency_responses['en'])
        return random.choice(responses)
