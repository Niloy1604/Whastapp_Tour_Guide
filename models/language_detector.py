import re
import json
import os
from langdetect import detect
from typing import Tuple, Dict, List, Optional

class QuickLanguageDetector:
    def __init__(self):
        # Load comprehensive language data
        self.language_data = self._load_language_data()
        self.supported_languages = list(self.language_data.get('supported_languages', {}).keys())
        
        # Enhanced Unicode patterns from languages.json
        self.script_patterns = {}
        self.keyword_patterns = {}
        self.strong_indicators = {}
        
        self._initialize_detection_patterns()
        print(f"âœ… Language detector initialized with {len(self.supported_languages)} languages")

    def _load_language_data(self) -> Dict:
        """Load comprehensive language data from JSON."""
        try:
            lang_file = os.path.join('data', 'languages.json')
            with open(lang_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âŒ Failed to load languages.json: {e}")
            return self._get_fallback_language_data()

    def _get_fallback_language_data(self) -> Dict:
        """Fallback language data if JSON fails to load."""
        return {
            'supported_languages': {
                'en': {'name': 'English', 'tts_supported': True, 'stt_supported': True},
                'hi': {'name': 'Hindi', 'tts_supported': True, 'stt_supported': True},
                'bn': {'name': 'Bengali', 'tts_supported': True, 'stt_supported': True}
            }
        }

    def _initialize_detection_patterns(self):
        """Initialize detection patterns from language data."""
        
        # Unicode script patterns
        self.script_patterns = {
            'hi': r'[\u0900-\u097F]+',   # Devanagari (Hindi, Marathi)
            'bn': r'[\u0980-\u09FF]+',   # Bengali script  
            'ta': r'[\u0B80-\u0BFF]+',   # Tamil script
            'te': r'[\u0C00-\u0C7F]+',   # Telugu script
            'gu': r'[\u0A80-\u0AFF]+',   # Gujarati script
            'kn': r'[\u0C80-\u0CFF]+',   # Kannada script
            'ml': r'[\u0D00-\u0D7F]+',   # Malayalam script
            'mr': r'[\u0900-\u097F]+',   # Marathi (shares Devanagari)
            'pa': r'[\u0A00-\u0A7F]+',   # Punjabi (Gurmukhi)
            'or': r'[\u0B00-\u0B7F]+',   # Odia script
            'as': r'[\u0980-\u09FF]+',   # Assamese (similar to Bengali)
            'ur': r'[\u0600-\u06FF]+',   # Arabic/Urdu script
        }

        # Enhanced keyword patterns with sample phrases from languages.json
        for lang_code, lang_info in self.language_data.get('supported_languages', {}).items():
            sample_phrases = lang_info.get('sample_phrases', {})
            
            # Extract keywords from sample phrases
            keywords = []
            for phrase in sample_phrases.values():
                if isinstance(phrase, str):
                    # Split into words and add to keywords
                    words = phrase.split()
                    keywords.extend([word.strip('.,!?') for word in words if len(word.strip('.,!?')) > 2])
            
            if keywords:
                self.keyword_patterns[lang_code] = keywords

        # Strong indicators for high-confidence detection
        self.strong_indicators = {
            'hi': ['à¤°à¤¾à¤œà¤¸à¥à¤¥à¤¾à¤¨', 'à¤œà¤¯à¤ªà¥à¤°', 'à¤•à¤¿à¤²à¥‡', 'à¤¬à¤¤à¤¾à¤“', 'à¤¦à¤¿à¤²à¥à¤²à¥€', 'à¤®à¥à¤‚à¤¬à¤ˆ', 'à¤­à¤¾à¤°à¤¤', 'à¤•à¤¹à¤¾à¤¨à¥€', 'à¤¸à¥à¤¨à¤¾à¤“'],
            'bn': ['à¦•à§‹à¦¥à¦¾à¦¯à¦¼', 'à¦•à§‡à¦²à§à¦²à¦¾', 'à¦²à¦¾à¦²', 'à¦¬à¦²à§à¦¨', 'à¦¸à¦®à§à¦ªà¦°à§à¦•à§‡', 'à¦¬à¦¾à¦‚à¦²à¦¾à¦¦à§‡à¦¶', 'à¦•à¦²à¦•à¦¾à¦¤à¦¾', 'à¦•à¦¹à¦¾à¦¨à§€'],
            'ta': ['à®šà¯Šà®²à¯à®²à¯à®™à¯à®•à®³à¯', 'à®•à¯‹à®Ÿà¯à®Ÿà¯ˆ', 'à®šà®¿à®µà®ªà¯à®ªà¯', 'à®ªà®±à¯à®±à®¿', 'à®¤à®®à®¿à®´à¯à®¨à®¾à®Ÿà¯', 'à®šà¯†à®©à¯à®©à¯ˆ', 'à®•à®¤à¯ˆ'],
            'te': ['à°šà±†à°ªà±à°ªà°‚à°¡à°¿', 'à°—à±à°°à°¿à°‚à°šà°¿', 'à°•à±‹à°Ÿ', 'à°Žà°°à±à°°', 'à°¤à±†à°²à°‚à°—à°¾à°£', 'à°¹à±ˆà°¦à°°à°¾à°¬à°¾à°¦à±', 'à°•à°¥'],
            'ml': ['à´ªà´±à´¯àµ‚', 'à´•àµà´±à´¿à´šàµà´šàµ', 'à´•àµ‹à´Ÿàµà´Ÿ', 'à´šàµà´µà´¨àµà´¨', 'à´•àµ‡à´°à´³à´‚', 'à´•àµŠà´šàµà´šà´¿', 'à´•à´¥'],
            'kn': ['à²¹à³‡à²³à²¿', 'à²¬à²—à³à²—à³†', 'à²•à³‹à²Ÿà³†', 'à²•à³†à²‚à²ªà³', 'à²•à²°à³à²¨à²¾à²Ÿà²•', 'à²¬à³†à²‚à²—à²³à³‚à²°à³', 'à²•à²¥à³†'],
            'gu': ['àª•àª¹à«‹', 'àªµàª¿àª¶à«‡', 'àª•àª¿àª²à«àª²à«‹', 'àª²àª¾àª²', 'àª—à«àªœàª°àª¾àª¤', 'àª…àª®àª¦àª¾àªµàª¾àª¦', 'àªµàª¾àª°à«àª¤àª¾'],
            'mr': ['à¤¸à¤¾à¤‚à¤—à¤¾', 'à¤¬à¤¦à¥à¤¦à¤²', 'à¤•à¤¿à¤²à¥à¤²à¤¾', 'à¤²à¤¾à¤²', 'à¤®à¤¹à¤¾à¤°à¤¾à¤·à¥à¤Ÿà¥à¤°', 'à¤®à¥à¤‚à¤¬à¤ˆ', 'à¤—à¥‹à¤·à¥à¤Ÿ'],
            'pa': ['à¨•à¨¹à¨¿à©°à¨¦à©‡', 'à¨¬à¨¾à¨°à©‡', 'à¨•à¨¿à¨²à©à¨¹à¨¾', 'à¨²à¨¾à¨²', 'à¨ªà©°à¨œà¨¾à¨¬', 'à¨šà©°à¨¡à©€à¨—à©œà©à¨¹'],
            'or': ['à¬•à­à¬¹à¬¨à­à¬¤à­', 'à¬¬à¬¿à¬·à­Ÿà¬°à­‡', 'à¬¦à­à¬°à­à¬—', 'à¬²à¬¾à¬²à­', 'à¬“à¬¡à¬¼à¬¿à¬¶à¬¾'],
            'as': ['à¦•à¦“à¦•', 'à¦¬à¦¿à¦·à¦¯à¦¼à§‡', 'à¦¦à§à§°à§à¦—', 'à§°à¦™à¦¾', 'à¦…à¦¸à¦®'],
            'ur': ['Ø¨ØªØ§Ø¦ÛŒÚº', 'Ú©Û’ Ø¨Ø§Ø±Û’', 'Ù‚Ù„Ø¹Û', 'Ù„Ø§Ù„', 'Ø§Ø±Ø¯Ùˆ'],
            'en': ['tell', 'about', 'fort', 'red', 'story', 'india', 'explore', 'visit']
        }

    def detect_language(self, text: str) -> Tuple[str, float]:
        """Enhanced language detection with priority-based approach."""
        if not text or not text.strip():
            return ('en', 0.0)

        print(f"ðŸ” Detecting language for: '{text}'")

        # Method 1: Strong indicators check (highest priority)
        strong_result = self._check_strong_indicators(text)
        if strong_result[1] > 0.0:
            print(f"ðŸŽ¯ Strong indicator detection: {strong_result}")
            return strong_result

        # Method 2: Script detection (high priority)
        script_result = self._detect_by_script(text)
        print(f"ðŸ“ Script detection: {script_result}")
        if script_result[1] > 0.2:
            return script_result

        # Method 3: Keyword matching from sample phrases (medium priority)
        keyword_result = self._detect_by_keywords(text)
        print(f"ðŸ”‘ Keyword detection: {keyword_result}")
        if keyword_result[1] > 0.15:
            return keyword_result

        # Method 4: langdetect with corrections (lowest priority)
        try:
            detected = detect(text)
            print(f"ðŸŒ Langdetect result: {detected}")
            
            # Fix common misdetections
            if detected in ['nl', 'no', 'da', 'sv', 'de']:
                # Check if it might be Bengali
                if re.search(self.script_patterns.get('bn', ''), text):
                    print(f"ðŸ”„ Correcting {detected} -> bn")
                    return ('bn', 0.8)
            
            # Return langdetect result if it's a supported language
            if detected in self.supported_languages:
                return (detected, 0.7)
            
        except Exception as e:
            print(f"âŒ Langdetect error: {e}")

        # Default to English
        print("ðŸ”„ Defaulting to English")
        return ('en', 0.0)

    def _check_strong_indicators(self, text: str) -> Tuple[str, float]:
        """Check for strong language-specific indicators."""
        text_lower = text.lower()
        
        for lang, indicators in self.strong_indicators.items():
            matches = sum(1 for indicator in indicators if indicator in text)
            if matches > 0:
                confidence = min(matches * 0.5, 1.0)
                return (lang, confidence)
        
        return ('en', 0.0)

    def _detect_by_script(self, text: str) -> Tuple[str, float]:
        """Detect language by Unicode script patterns."""
        total_chars = len(text)
        if total_chars == 0:
            return ('en', 0.0)

        best_lang = 'en'
        highest_confidence = 0.0

        for lang, pattern in self.script_patterns.items():
            matches = re.findall(pattern, text)
            if matches:
                char_count = sum(len(match) for match in matches)
                confidence = char_count / total_chars
                
                if confidence > highest_confidence:
                    best_lang = lang
                    highest_confidence = confidence

        return (best_lang, highest_confidence)

    def _detect_by_keywords(self, text: str) -> Tuple[str, float]:
        """Detect language by keywords from sample phrases."""
        words = text.split()
        if not words:
            return ('en', 0.0)

        best_lang = 'en'
        best_score = 0.0

        for lang, keywords in self.keyword_patterns.items():
            matches = 0
            for word in words:
                for keyword in keywords:
                    if keyword in word:
                        matches += 1
                        break
            
            if matches > 0:
                score = matches / len(words)
                if score > best_score:
                    best_lang = lang
                    best_score = score

        return (best_lang, best_score)

    def get_language_info(self, lang_code: str) -> Dict:
        """Get comprehensive language information."""
        return self.language_data.get('supported_languages', {}).get(lang_code, {})

    def is_voice_supported(self, lang_code: str) -> bool:
        """Check if voice (TTS/STT) is supported for language."""
        lang_info = self.get_language_info(lang_code)
        return lang_info.get('tts_supported', False) and lang_info.get('stt_supported', False)

    def get_language_name(self, code: str) -> str:
        """Get full language name from code."""
        lang_info = self.get_language_info(code)
        return lang_info.get('name', 'English')

    def get_native_name(self, code: str) -> str:
        """Get native language name."""
        lang_info = self.get_language_info(code)
        return lang_info.get('native_name', 'English')

    def get_supported_languages(self) -> List[str]:
        """Get list of supported language codes."""
        return self.supported_languages

    def get_greeting(self, lang_code: str, style: str = 'formal') -> str:
        """Get culturally appropriate greeting."""
        greetings = self.language_data.get('cultural_greetings', {}).get(style, {})
        return greetings.get(lang_code, greetings.get('en', 'Welcome!'))
